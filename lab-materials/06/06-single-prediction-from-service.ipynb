{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51475f0a-7266-475e-96ed-d617d5380221",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q optimum[onnxruntime]==1.23.3 transformers==4.46.3 torch==2.2.2+cu121\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a7498-c501-401b-9dab-8be1aa49528e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## we need some preprocessing functions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e949b6a8-2c04-418b-bd5c-dc0a082b7b67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from optimum.onnxruntime import ORTModelForImageClassification\n",
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "# Load and export the model to ONNX\n",
    "model = ORTModelForImageClassification.from_pretrained(\"rh-ai-bu/wildfire01\", export=True)\n",
    "\n",
    "# Load the feature extractor\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"rh-ai-bu/wildfire01\")\n",
    "\n",
    "# Create an ONNX-based pipeline\n",
    "from optimum.pipelines import pipeline\n",
    "onnx_pipeline = pipeline(\"image-classification\", model=model, feature_extractor=feature_extractor, accelerator=\"ort\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542876e6-a03f-452a-adf4-1d2f05f6b1d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to list all the things it can do:\n",
    "print(dir(onnx_pipeline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7475db-1eea-4b82-b800-fd07f0a80d86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "help(onnx_pipeline.preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e69725e-ac2d-42ff-b0ff-3a1fd5ce071f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "help(onnx_pipeline.postprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b57f0-a88e-4e0d-bdce-ed56c6142be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "onnx_pipeline.save_pretrained(\"onnx_pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c6bea-b3dc-48ac-bc2d-a3d9cd8494b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# image = \"pic2.jpg\"\n",
    "# Import the function from the script\n",
    "from get_random_image import get_random_image\n",
    "\n",
    "# Call the function\n",
    "image = get_random_image()\n",
    "\n",
    "# Print the selected image path\n",
    "print(image)\n",
    "\n",
    "image = \"/opt/app-root/src/ai-mazing-race/lab-materials/06/04-wildfire-sample/wildfire_types_image_detection_sample/val/fire/Smoke_from_fires/50323627386_af76996942_o.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50441442-10ea-4bc3-94f4-e96010d6763e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## show the image we are working with\n",
    "from IPython.display import Image, display\n",
    "display(Image(filename=image, width=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ba39b-0efe-4d86-b51f-abd6291f057d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_preprocessed = onnx_pipeline.preprocess(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c7f88a-df0d-4e4f-90df-1c7b9856634b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_preprocessed[\"pixel_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8bfedf-8263-4b7a-ac82-14f30f6e0b87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## figure out the precise URL we need to hit:\n",
    "\n",
    "import subprocess\n",
    "\n",
    "def run_command(command):\n",
    "    \"\"\"Run an OS command and return its output, handling errors.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.check_output(command, shell=True, text=True).strip()\n",
    "        return result\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error occurred while running the command '{command}': {e}\")\n",
    "        return None\n",
    "\n",
    "# Commands to run\n",
    "get_IS_name = \"oc get inferenceservice -o jsonpath='{.items[0].metadata.name}'\"\n",
    "get_IS_URL = \"oc get inferenceservice -o jsonpath='{.items[0].status.url}'\"\n",
    "\n",
    "# Retrieve results\n",
    "deployed_model_name = run_command(get_IS_name)\n",
    "infer_endpoint = run_command(get_IS_URL)\n",
    "\n",
    "# Print the results\n",
    "if deployed_model_name:\n",
    "    print(\"Inference Service Name:\", deployed_model_name)\n",
    "else:\n",
    "    print(\"Failed to retrieve Inference Service Name.\")\n",
    "\n",
    "if infer_endpoint:\n",
    "    print(\"Inference Service URL:\", infer_endpoint)\n",
    "else:\n",
    "    print(\"Failed to retrieve Inference Service URL.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94e54b2-c377-4f54-93bb-f5bf04e17aec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "infer_url = f\"{infer_endpoint}/v2/models/{deployed_model_name}/infer\"\n",
    "print(infer_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a5a067-f46c-4a2f-a45f-765b03e1b13c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rest_request(data):\n",
    "    json_data = {\n",
    "        \"inputs\": [\n",
    "            {\n",
    "                \"name\": \"pixel_values\",\n",
    "                \"shape\": image_preprocessed[\"pixel_values\"].shape,\n",
    "                \"datatype\": \"FP32\",\n",
    "                \"data\": data\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    start_time = time.time()  # Record the start time\n",
    "    response = requests.post(infer_url, json=json_data, verify=True)\n",
    "    end_time = time.time()  # Record the end time\n",
    "\n",
    "    # Calculate and print the response time\n",
    "    response_time = end_time - start_time\n",
    "    print(f\"Response time: {response_time:.6f} seconds\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c81d1a6-6dbc-42f2-a5ac-84580e8cdbeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = rest_request(image_preprocessed[\"pixel_values\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb873e-e587-4a73-83eb-9d9df41680a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c8ddf8-4dac-4fc9-b731-db1791248d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
