{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "567631bb-afea-4d6c-8050-aff81667b103",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b0a14a-714a-4c10-9eae-ddc9a0e40c86",
   "metadata": {},
   "source": [
    "## Install and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46607d8f-df65-4012-9baf-787f18e0185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install \"numpy==1.26.4\" \"tensorflow==2.18.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116a7766-9f84-46d9-9b76-6ab04e17d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18df957c-fd6d-45a2-8f13-05206d55b3cd",
   "metadata": {},
   "source": [
    "## How does the dataset look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b4bb1e-bf3a-47a9-8b35-f82204676c2b",
   "metadata": {},
   "source": [
    "### These are the features we have available in the dataset\n",
    "**name** - (String) The name of the furniture.  \n",
    "**category** - (String) What type of furniture it is. This will be converted to multiple columns with 1 or 0 if it's that category or not (to make it easy for the AI to read).  \n",
    "**price** - (Float) The current price of the product.  \n",
    "**old_price** - (Float) A previous price of the product, same as the current price in many cases.  \n",
    "**sellable_online** - (Bool) If the item is sellable online, this will be True.  \n",
    "**other_colors** - (Bool) If the item has other color variants, this will be True.  \n",
    "**width** - (Float) The width of the item, if applicable.  \n",
    "**depth** - (Float) The depth of the item, if applicable.  \n",
    "**height** - (Float) The height of the item, if applicable.  \n",
    "**discounted** - (Int) Takes 1 if the item is discounted, 0 otherwise.  \n",
    "**width_d** - (Int) Takes 1 if it had a weight or 0 if it was NaN and was assigned a value through interpolation.  \n",
    "**height_d** -  (Int) Takes 1 if it had a height or 0 if it was NaN and was assigned a value through interpolation.  \n",
    "**depth_d** -  (Int) Takes 1 if it had a depth or 0 if it was NaN and was assigned a value through interpolation.  \n",
    "**discount_amount** - (Float) How much to discount the item with.  \n",
    "**size** - (Float) The total size of the item, 1 in case none of the shapes were given.  \n",
    "\n",
    "In the cell below, you get some examples of how this looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e52f108-3fea-471c-928a-4e53399d78d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/clean_OMEA_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533dd37c-da79-4269-b094-191c30971780",
   "metadata": {},
   "source": [
    "## Time to pick your features!\n",
    "Choose the features you want to include in your training.  \n",
    "We need to choose input features as well as an output feature (we can't use Category as output).  \n",
    "\n",
    "NOTE: You are not allowed to include both *discount_amount* and *old_price* in INPUT_FEATURES.  \n",
    "Quiz: Why would this be a pointless excerice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f03f7f7e-0b14-498d-8858-67184501dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FEATURES = [\n",
    "    # \"name\", # The model can't handle freeform names\n",
    "    \"category\",\n",
    "    # \"price\",\n",
    "    # \"old_price\",\n",
    "    \"sellable_online\",\n",
    "    \"other_colors\",\n",
    "    # \"short_description\", # The model can't handle freeform descriptions\n",
    "    \"width\",\n",
    "    \"height\",\n",
    "    \"depth\",\n",
    "    \"width_d\",\n",
    "    \"height_d\",\n",
    "    \"depth_d\",\n",
    "    \"discounted\",\n",
    "    \"discount_amount\",\n",
    "    \"size\"\n",
    "]\n",
    "PREDICT_TARGET = \"price\"\n",
    "SAVE_FOLDER = \"new_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e252e76-ddd8-4dd1-9c15-ad6098d5f0fd",
   "metadata": {},
   "source": [
    "## Create the training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e8580-155d-4498-ad80-d8a55c53ee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import utils\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b145f0-4016-4fc9-b9c9-0f0b3359ac0b",
   "metadata": {},
   "source": [
    "Let's start by processing our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137013ac-1be1-4db1-a2ac-cb8b6a252085",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_to_scale = ['price', 'old_price', 'width', 'height', 'depth', 'discount_amount', 'size']\n",
    "items_to_encode = ['sellable_online', 'other_colors']\n",
    "items_to_one_hot_encode = ['category']\n",
    "\n",
    "scalers = {}\n",
    "encoders = {}\n",
    "\n",
    "for i in items_to_scale:\n",
    "    if i in INPUT_FEATURES or i == PREDICT_TARGET:\n",
    "        scalers[i] = MinMaxScaler()\n",
    "        df[[i]] = scalers[i].fit_transform(df[[i]])\n",
    "    else:\n",
    "        df = df.drop(i, axis=1)\n",
    "\n",
    "for i in items_to_encode:\n",
    "    if i in INPUT_FEATURES or i == PREDICT_TARGET:\n",
    "        encoders[i] = LabelEncoder()\n",
    "        df[i] = encoders[i].fit_transform(df[i])\n",
    "    else:\n",
    "        df = df.drop(i, axis=1)\n",
    "\n",
    "for i in items_to_one_hot_encode:\n",
    "    if i in INPUT_FEATURES or i == PREDICT_TARGET:\n",
    "        df = pd.get_dummies(df, columns=[i])\n",
    "    else:\n",
    "        df = df.drop(i, axis=1)\n",
    "\n",
    "df = df.drop([\"name\", \"short_description\"], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8642d0-a7a1-478c-b99c-ac602a9873af",
   "metadata": {},
   "source": [
    "## Train and test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e8f62-5d95-4838-8729-4983363e057c",
   "metadata": {},
   "source": [
    "Now we can split our dataset into training and testing.  \n",
    "The training will be what we train our model on, and the test dataset will be what we later run the tests on.  \n",
    "We purposfully don't show the test data to the model during training so that it can be used to see how well our model performs on unseen data, i.e. how well it can generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1869478-4fd4-4f8e-9c43-ebb89f6481e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, shuffle=True, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fb4b3a-a481-4d37-8144-4bac730a55fa",
   "metadata": {},
   "source": [
    "## Create and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b974015b-86c3-4346-bff5-d2faf9ce51a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.set_random_seed(112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "134873bd-1e85-4fa6-a60b-9b275b451583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(my_learning_rate):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(len(df_train.columns)-1,)),\n",
    "        tf.keras.layers.Dense(20, activation='relu', name='Hidden1'),\n",
    "        tf.keras.layers.Dense(10, activation='relu', name='Hidden2'),\n",
    "        tf.keras.layers.Dense(1, name='Output')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=my_learning_rate),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d81eee-016d-41d7-bdc5-0cbcfdcce620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 20\n",
    "batch_size = 2\n",
    "\n",
    "# Create the model\n",
    "model = create_model(learning_rate)\n",
    "\n",
    "features = df_train.drop(PREDICT_TARGET, axis=1)\n",
    "labels = df_train[[PREDICT_TARGET]]\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(features.values, labels.values, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f125bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Training Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9a3060-d5c3-4a6d-a164-b9ef4d0eab08",
   "metadata": {},
   "source": [
    "## Save the artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2726dbe-1011-4136-a724-5e14cc2af951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and artifacts\n",
    "Path(SAVE_FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model.save(f\"{SAVE_FOLDER}/model.keras\")\n",
    "\n",
    "with open(f\"{SAVE_FOLDER}/scalers.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(scalers, handle)\n",
    "with open(f\"{SAVE_FOLDER}/encoders.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(encoders, handle)\n",
    "\n",
    "df_train.to_parquet(f\"{SAVE_FOLDER}/X_train.parquet\")\n",
    "df_test.to_parquet(f\"{SAVE_FOLDER}/X_test.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
